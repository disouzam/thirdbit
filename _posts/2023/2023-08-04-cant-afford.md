---
title: "Can't Afford"
date: 2023-08-04
year: 2023
---

I had a conversation this week with someone who has been working hard for years
to get more students from marginalized groups into tech jobs.
He talked a bit about their curriculum and their partnerships with various colleges and companies,
then mentioned that they're going to be investing heavily in AI for teaching in the coming year.
When I said that I had concerns about the ethical issues involved in that,
his response was (a) students are using these tools anyway
and (b) they can't afford to be fussy about ethicsâ€”they need jobs.

I tried to push back but he wouldn't budge.
The students he and his group are trying to help come from low-income backgrounds,
they have to do extra work
to overcome barriers that middle-class white and Asian kids from top-100 schools don't,
and a job in tech would literally be life-changing for them and their families.
For him,
my concerns about implicit bias in LLMs or the working conditions of the people creating the training sets
are another case of someone comfortable centering themselves at the expense of others.

It reminded me a conversation I overheard many years ago about healthy food.
The person beside me kept saying that
everyone would be better off if they ate a balanced diet and organic produce,
until eventually the person opposite her
(who taught at a middle school in a low-income neighborhood)
lost her temper and said,
"It would take two hours each way for my kids' parents
to get to the grocery store in your neighborhood,
and even if they went they couldn't afford to buy what's there.
Who are you to tell them what to eat?"

I believe that AI tools are going to change programming
just as much as SourceForge and Stack Overflow did.
I also believe that the furore over AI is Silicon Valley hype
and that it would be reckless to deploy anything at scale today
when so many technical, ethical, and regulatory aspects
are going to change on a scale of weeks or months.
But those are just beliefs;
what I need to do is spend a year watching people experiment with these tools
in the way that they experimented with the web in the 1990s
and *then* form an opinion.
To paraphrase William Gibson,
the classroom finds its own uses for things.
I think we'd all be better off if we gave the courageous and the curious
a year to figure out what these things are actually good for
before we started trying to design a future that includes them.
